<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Sound Debugger</title>
    <script src="/env-config.js"></script>
    <style>
        body { font-family: system-ui, sans-serif; padding: 20px; background: #f0f9ff; }
        .controls { display: flex; flex-direction: column; gap: 10px; max-width: 600px; margin-bottom: 20px; }
        input, select, button { padding: 10px; font-size: 1rem; border-radius: 5px; border: 1px solid #ccc; }
        button { background: #3b82f6; color: white; border: none; cursor: pointer; font-weight: bold; }
        button:hover { background: #2563eb; }
        button.secondary { background: #64748b; }
        #log { white-space: pre-wrap; word-break: break-all; background: #1e293b; color: #a5f3fc; padding: 15px; border-radius: 8px; max-height: 500px; overflow-y: auto; font-family: monospace; }
        .status { margin-bottom: 10px; font-weight: bold; }
    </style>
</head>
<body>
    <h1>ðŸ”Š Advanced Sound Debugger</h1>
    
    <div class="controls">
        <label>
            Text to speak:
            <input type="text" id="textInput" value="Hello world" style="width: 100%;">
        </label>

        <label>
            Model:
            <select id="modelSelect">
                <option value="gemini-2.5-flash-preview-tts" selected>gemini-2.5-flash-preview-tts (TTS)</option>
                <option value="gemini-2.0-flash-exp">gemini-2.0-flash-exp (Multimodal)</option>
                <option value="gemini-1.5-flash">gemini-1.5-flash (Text Only Test)</option>
            </select>
        </label>

        <label>
            Voice:
            <select id="voiceSelect">
                <option value="Kore" selected>Kore</option>
                <option value="Puck">Puck</option>
                <option value="Fenrir">Fenrir</option>
                <option value="Aoede">Aoede</option>
            </select>
        </label>

        <label>
            <input type="checkbox" id="useSpeechConfig" checked> Send Speech Config
        </label>
        
        <label>
            <input type="checkbox" id="useResponseModalities" checked> Send responseModalities: ["AUDIO"]
        </label>

        <div style="display: flex; gap: 10px;">
            <button onclick="runTest()">â–¶ Run Test</button>
            <button class="secondary" onclick="clearLog()">Clear Log</button>
        </div>
    </div>

    <div id="status" class="status">Ready</div>
    <div id="log">Logs will appear here...</div>

    <script type="module">
        import { GoogleGenAI } from "https://esm.sh/@google/genai@^1.41.0";

        const logDiv = document.getElementById('log');
        const statusDiv = document.getElementById('status');
        
        window.clearLog = () => {
            logDiv.innerText = '';
        };

        function log(msg) {
            console.log(msg);
            logDiv.innerText += msg + '\n----------------\n';
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        window.runTest = async () => {
            const text = document.getElementById('textInput').value;
            const modelName = document.getElementById('modelSelect').value;
            const voice = document.getElementById('voiceSelect').value;
            const useSpeechConfig = document.getElementById('useSpeechConfig').checked;
            const useResponseModalities = document.getElementById('useResponseModalities').checked;

            statusDiv.innerText = "Running...";
            log(`Starting test with:\nModel: ${modelName}\nText: "${text}"\nVoice: ${voice}\nSpeechConfig: ${useSpeechConfig}\nResponseModalities: ${useResponseModalities}`);

            try {
                const apiKey = (window._env_ && window._env_.API_KEY) || '';
                if (!apiKey) {
                    log("ERROR: No API Key found!");
                    return;
                }
                log(`API Key: ${apiKey.substring(0, 5)}...`);

                const ai = new GoogleGenAI({ apiKey });
                
                const config = {};
                if (useResponseModalities) {
                    config.responseModalities = ["AUDIO"];
                }
                if (useSpeechConfig) {
                    config.speechConfig = {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: voice },
                        },
                    };
                }

                // Remove config if empty
                const finalConfig = Object.keys(config).length > 0 ? config : undefined;

                log("Sending request...");
                const response = await ai.models.generateContent({
                    model: modelName,
                    contents: [{ parts: [{ text: text }] }],
                    config: finalConfig
                });

                log("Response received!");
                log(JSON.stringify(response, null, 2));

                // Check finishReason
                const candidate = response.candidates?.[0];
                if (candidate?.finishReason) {
                    log(`Finish Reason: ${candidate.finishReason}`);
                }

                // Try to play audio if present
                const part = candidate?.content?.parts?.[0];
                if (part?.inlineData?.data) {
                    log(`Audio found! Length: ${part.inlineData.data.length}`);
                    playAudio(part.inlineData.data);
                } else if (part?.text) {
                    log(`Text received: "${part.text}"`);
                } else {
                    log("No content parts found.");
                }

                statusDiv.innerText = "Done";

            } catch (e) {
                statusDiv.innerText = "Error";
                log("EXCEPTION: " + e.toString());
                console.error(e);
            }
        };

        function playAudio(base64) {
            try {
                const binaryString = atob(base64);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);

                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const dataInt16 = new Int16Array(bytes.buffer);
                const audioBuffer = ctx.createBuffer(1, dataInt16.length, 24000); // 24kHz for Gemini
                const channelData = audioBuffer.getChannelData(0);
                for (let i = 0; i < dataInt16.length; i++) {
                    channelData[i] = dataInt16[i] / 32768.0;
                }

                const source = ctx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(ctx.destination);
                source.start();
                log("Audio playing...");
            } catch (e) {
                log("Audio Playback Error: " + e.message);
            }
        }
    </script>
</body>
</html>
