<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–¢–µ—Å—Ç –∑–≤—É–∫—É (Gemini TTS)</title>
    <script src="/env-config.js"></script>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; background: #f0f9ff; }
        button { font-size: 1.5rem; padding: 20px 40px; border-radius: 15px; border: none; background: #3b82f6; color: white; cursor: pointer; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        button:active { transform: scale(0.95); }
        #status { margin-top: 20px; font-weight: bold; color: #333; }
        #log { margin-top: 20px; font-size: 0.8rem; color: #666; max-width: 80%; white-space: pre-wrap; word-break: break-all; }
    </style>
</head>
<body>
    <h1>üîä –¢–µ—Å—Ç –∑–≤—É–∫—É</h1>
    <button id="btn">–°–∫–∞–∑–∞—Ç–∏ "–ê"</button>
    <div id="status">–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É</div>
    <div id="log"></div>

    <script type="module">
        import { GoogleGenAI } from "https://esm.sh/@google/genai@^1.41.0";

        const logDiv = document.getElementById('log');
        const statusDiv = document.getElementById('status');

        function log(msg) {
            console.log(msg);
            logDiv.innerText += msg + '\n';
        }

        async function speak() {
            try {
                statusDiv.innerText = "–ó–∞–ø–∏—Ç –¥–æ Gemini...";
                log("–ü–æ—á–∏–Ω–∞—é —Ç–µ—Å—Ç...");

                const apiKey = (window._env_ && window._env_.API_KEY) || '';
                if (!apiKey) {
                    throw new Error("API Key –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ window._env_.API_KEY");
                }
                log("API Key –∑–Ω–∞–π–¥–µ–Ω–æ (–ø–µ—Ä—à—ñ 4 —Å–∏–º–≤–æ–ª–∏): " + apiKey.substring(0, 4) + "...");

                const ai = new GoogleGenAI({ apiKey });
                log("–ú–æ–¥–µ–ª—å: gemini-2.5-flash-preview-tts");

                const response = await ai.models.generateContent({
                    model: "gemini-2.5-flash-preview-tts",
                    contents: [{ parts: [{ text: "–ê" }] }],
                    config: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            voiceConfig: {
                                prebuiltVoiceConfig: { voiceName: 'Kore' },
                            },
                        },
                    },
                });

                log("–í—ñ–¥–ø–æ–≤—ñ–¥—å –æ—Ç—Ä–∏–º–∞–Ω–æ.");
                const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;

                if (!base64Audio) {
                    throw new Error("–ù–µ–º–∞—î –∞—É–¥—ñ–æ –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ");
                }
                log("–ê—É–¥—ñ–æ –¥–∞–Ω—ñ (base64) –æ—Ç—Ä–∏–º–∞–Ω–æ, –¥–æ–≤–∂–∏–Ω–∞: " + base64Audio.length);

                // Decode and Play
                const binaryString = atob(base64Audio);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                log("–°—Ç–≤–æ—Ä–µ–Ω–Ω—è AudioContext...");
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                if (ctx.state === 'suspended') {
                    await ctx.resume();
                    log("AudioContext resumed");
                }

                // Decode int16 PCM (24kHz)
                const dataInt16 = new Int16Array(bytes.buffer);
                const frameCount = dataInt16.length;
                const audioBuffer = ctx.createBuffer(1, frameCount, 24000);
                const channelData = audioBuffer.getChannelData(0);
                for (let i = 0; i < frameCount; i++) {
                    channelData[i] = dataInt16[i] / 32768.0;
                }

                log("–í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è...");
                const source = ctx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(ctx.destination);
                source.start();

                statusDiv.innerText = "–ì—Ä–∞—î –∑–≤—É–∫! üé∂";
                log("–£—Å–ø—ñ—Ö!");

            } catch (e) {
                console.error(e);
                statusDiv.innerText = "–ü–æ–º–∏–ª–∫–∞: " + e.message;
                log("ERROR: " + e.toString());
            }
        }

        document.getElementById('btn').addEventListener('click', speak);
    </script>
</body>
</html>
